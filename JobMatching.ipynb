{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7245d758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\AISOHackathon\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2103 base docs\n",
      "Prepared 12684 chunks\n",
      "Example IDs: ['4188f152-ff0c-432f-b179-5bd032c38916', '96864f78-1b7d-451e-95e2-367b7f092fb2', '26eddbca-3d25-4127-aebd-532aabf6c81a']\n",
      "Done indexing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters  import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "# 1) Load & sanitize\n",
    "df = pd.read_csv(\"joblist_clean_for_rag.csv\")\n",
    "df = df.fillna(\"\").reset_index(drop=False).rename(columns={\"index\": \"doc_id\"})\n",
    "df[\"doc_id\"] = df[\"doc_id\"].astype(str)\n",
    "\n",
    "def row_to_doc(row):\n",
    "    content = (\n",
    "        f\"Title: {row['title']}\\n\"\n",
    "        f\"Company: {row['company']}\\n\"\n",
    "        f\"Location: {row['location']}\\n\"\n",
    "        f\"Remote: {row['remote']}\\n\"\n",
    "        f\"Department: {row['department']}\\n\"\n",
    "        f\"Description:\\n{row['description']}\"\n",
    "    ).strip()\n",
    "    metadata = {\n",
    "        \"doc_id\": row[\"doc_id\"],\n",
    "        \"title\": row[\"title\"],\n",
    "        \"company\": row[\"company\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"remote\": row[\"remote\"],\n",
    "        \"department\": row[\"department\"],\n",
    "    }\n",
    "    return Document(page_content=content, metadata=metadata)\n",
    "\n",
    "base_docs = [row_to_doc(r) for _, r in df.iterrows()]\n",
    "print(f\"Loaded {len(base_docs)} base docs\")\n",
    "\n",
    "# 2) Chunk (so each embed is small)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,     # ~800–1200 chars is usually fine\n",
    "    chunk_overlap=150,   # small overlap for context continuity\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "chunked_docs = []\n",
    "for d in base_docs:\n",
    "    for i, ch in enumerate(splitter.split_text(d.page_content)):\n",
    "        md = dict(d.metadata)\n",
    "        md[\"chunk\"] = i\n",
    "        chunked_docs.append(Document(page_content=ch, metadata=md))\n",
    "\n",
    "print(f\"Prepared {len(chunked_docs)} chunks\")\n",
    "\n",
    "# 3) Embeddings (use the small model to cut cost/size)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "#embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "# 4) Chroma store\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"jobs_rag\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")\n",
    "\n",
    "# 5) Batch add to avoid per-request token overflow\n",
    "BATCH_SIZE = 100  # adjust if you still hit limits; smaller => safer\n",
    "ids = []\n",
    "for i in range(0, len(chunked_docs), BATCH_SIZE):\n",
    "    batch = chunked_docs[i:i+BATCH_SIZE]\n",
    "    ids.extend(vector_store.add_documents(batch))\n",
    "    # optional: print progress\n",
    "    # print(f\"Indexed {i+len(batch)}/{len(chunked_docs)}\")\n",
    "\n",
    "print(\"Example IDs:\", ids[:3])\n",
    "print(\"Done indexing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ddb4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "373 | Staff Backend Engineer (Python), AI Engineering: Agent Foundations  | gitlab | Remote, EMEA\n",
      "Multiple years of experience building Python Web Services in a multi-service environment ( e.g. FastAPI, Starlette)\n",
      "Proven ability to architect and lead complex technical projects from concept to production across distributed systems\n",
      "Strong experience with AI/ML technologies, including integration with large language models and understanding of prompt engineering\n",
      "Deep expertise in performance opti ...\n",
      "-----\n",
      "1667 | Software Engineer - Backend & Scalability | datadog | Paris, France\n",
      "What You’ll Do: \n",
      "Build and maintain reliable backend services that process and store large volumes of data\n",
      "Contribute to internal platforms, APIs, and tools that power distributed products\n",
      "Collaborate with experienced engineers to design and implement scalable system components\n",
      "Ship production code in languages like Go, Python, or Java\n",
      "Learn and apply distributed system patterns through hands-on d ...\n",
      "-----\n",
      "1094 | Sr. Manager, Engineering - Model Serving | databricks | San Francisco, California\n",
      "Drive architectural decisions and product design around latency, throughput, autoscaling, GPU/CPU placement, and cost optimization.\n",
      "Advocate for customer needs through direct engagement, ensuring engineering decisions translate to clear product impact.\n",
      "Promote best practices in code quality, testing, observability, and operational readiness.\n",
      "Foster a culture of excellence, inclusion, and continuou ...\n",
      "-----\n",
      "1620 | Senior Software Engineer - Backend & Scalability (Lisbon) | datadog | Lisbon, Portugal\n",
      "What You’ll Do: \n",
      "Design and build reliable backend services that handle high-throughput, globally distributed workloads\n",
      "Own core components that power products relied on by thousands of engineering teams worldwide\n",
      "Collaborate with other experienced engineers to evolve system architecture with a focus on scalability and resilience\n",
      "Learn and apply distributed systems design patterns in a production  ...\n",
      "-----\n",
      "1619 | Senior Software Engineer - Backend & Scalability | datadog | Madrid, Spain; Paris, France; Tel Aviv, Israel\n",
      "What You’ll Do: \n",
      "Design and build reliable backend services that handle high-throughput, globally distributed workloads\n",
      "Own core components that power products relied on by thousands of engineering teams worldwide\n",
      "Collaborate with other experienced engineers to evolve system architecture with a focus on scalability and resilience\n",
      "Learn and apply distributed systems design patterns in a production  ...\n"
     ]
    }
   ],
   "source": [
    "# 6) Retrieval example\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "query = \"senior Python backend engineer with experience in low-latency trading\"\n",
    "results = retriever.invoke(query)\n",
    "for r in results:\n",
    "    print(\"-----\")\n",
    "    print(r.metadata.get(\"doc_id\"), \"|\", r.metadata.get(\"title\"), \"|\", r.metadata.get(\"company\"), \"|\", r.metadata.get(\"location\"))\n",
    "    print(r.page_content[:400], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e4cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Company\": \"valtech\",\n",
      "  \"Job Title\": \"Solution Architect - Xstore\",\n",
      "  \"Remote\": \"not\",\n",
      "  \"Description\": \"Valtech is seeking a Solution Architect with 10+ years of experience to drive the architecture of Oracle Xstore POS and its ecosystem. This role involves defining end-to-end store system architecture, integrating with various platforms (ERP, CRM, e-commerce), and providing technical leadership. The architect will translate business requirements into scalable, secure, and future-ready solutions, conduct Proofs of Concept, and lead localization strategies. They will also support pre-sales activities and mentor project teams, acting as a trusted advisor to clients on retail transformation initiatives. The position emphasizes a growth mindset, collaboration, and a passion for experience innovation.\",\n",
      "  \"Requirements\": \"Bachelor's/Master's degree in Computer Science/Engineering or related field. 10-15 years IT experience with 5+ years as a Solution Architect in retail. Strong hands-on experience with Oracle Xstore POS and Oracle Retail solutions. Expertise in solution design, integration architecture, and scalability. Experience in large-scale global POS implementations. Deep understanding of store operations, retail workflows, and omnichannel processes. Technical knowledge in Java, middleware, APIs, databases, and cloud integration. Excellent leadership, communication, and presentation skills.\",\n",
      "  \"Email\": \"@valtech.com\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "  \"Company\": \"Valtech Solutions LLC\",\n",
      "  \"Job Title\": \"Technology Architect (Oracle POS Xstore)\",\n",
      "  \"Remote\": \"yes\",\n",
      "  \"Description\": \"Valtech Solutions LLC seeks a Technology Architect specializing in Oracle POS Xstore for a fully remote position within the United States. This role involves developing, modifying, and maintaining proprietary software systems for the retail sector, including QA responsibilities. The architect will collaborate with Solution and Application Architects to create design documentation, work with development teams using Agile methodologies to deliver software features, and assist in deploying software modules to various environments. The position also requires troubleshooting software defects and acting as a Subject Matter Expert in Xstore. The role reports to the Plano, TX headquarters.\",\n",
      "  \"Requirements\": \"Bachelor's degree in Computer Science, Information Systems, or related discipline with 3 years of experience as a Technical Architect or similar. Must have 3 years of experience with the Xstore Suite (Xadmin, Xcenter, Xservices, Xenvironment, Xstore, XMobile Tablet) and related areas such as customizations, configurations, UI changes, locale changes, DB issues, POS deployment, debugging, issue fixing, device configurations, and data mapping. Experience with payment integration (EFT Link/AJB to third parties like FreedomPay, SixPay, or TenderRetail) and 3 years of experience with PL/SQL and Oracle DB are required. One year of consulting experience is also needed. The position is 100% remote from any US location.\",\n",
      "  \"Email\": \"Please apply via the 'Apply Now' button on the job posting page.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "  \"Company\": \"valtech\",\n",
      "  \"Job Title\": \"Senior Quality Engineering Lead\",\n",
      "  \"Remote\": \"yes\",\n",
      "  \"Description\": \"Valtech Solutions LLC is seeking a Senior Quality Engineering Lead with expertise in Oracle XStore POS systems. This 100% remote role involves designing and implementing QA strategies, developing and executing test plans for POS systems and peripherals, and creating automation frameworks (POM, TDD, BDD, Hybrid). Responsibilities include script development using Selenium, Appium, and RestAssured, resolving technical challenges, providing hyper-care support, and collaborating with diverse teams and stakeholders. The role also requires client interaction and coordination with Oracle support for issue resolution and operational excellence.\",\n",
      "  \"Requirements\": \"Bachelor's degree in IT, Computer Science, or related field, with 5 years of experience in Oracle XStore POS testing, implementation, and upgrades. Must have 5 years of experience with XEnvironment, XCenter, XAdmin, XMobile, EFTLink, ORCE, and Payments integrations (Adyen, Verifone, Elavon). Requires 3 years of experience with POS applications, automation tools (Java, Selenium, HP UFT), Robotic Arm Automation, Oracle SQL, Putty, Winscp, Jira, HP ALM, Test Rail, programming languages (Java, Selenese, VBScript), CI/CD tools (Jenkins, Maven, ANT, Gradle, Bamboo), and Order/Warehouse Management Systems (Sterling).\",\n",
      "  \"Email\": \"nam.recruitment@valtech.com\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Index df by doc_id for fast lookup\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "        model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "        system_prompt=\"\"\"I will give you a job description, please quickly summarize this job in 200 words,reply like this in json format:\n",
    "         Company:\n",
    "         Job Title:\n",
    "         Remote:yes/not\n",
    "         Decription:\n",
    "         Requirements:   \n",
    "         Email:\n",
    "         \"\"\"\n",
    "    )\n",
    "df_by_id = df.set_index(\"doc_id\", drop=False)\n",
    "\n",
    "def format_full_row(row):\n",
    "    return (\n",
    "        f\"Title: {row['title']}\\n\"\n",
    "        f\"Company: {row['company']}\\n\"\n",
    "        f\"Location: {row['location']}\\n\"\n",
    "        f\"Remote: {row['remote']}\\n\"\n",
    "        f\"Department: {row['department']}\\n\"\n",
    "        f\"Description:\\n{row['description']}\"\n",
    "    ).strip()\n",
    "\n",
    "def retrieve_full_jobs_by_id(query, k=5):\n",
    "    chunks = retriever.invoke(query)\n",
    "    seen = set()\n",
    "    full = []\n",
    "    for ch in chunks:\n",
    "        did = ch.metadata[\"doc_id\"]\n",
    "        if did in seen:\n",
    "            continue\n",
    "        seen.add(did)\n",
    "        row = df_by_id.loc[did]\n",
    "        full.append(format_full_row(row))\n",
    "        if len(full) >= k:\n",
    "            break\n",
    "    return full\n",
    "\n",
    "# Example\n",
    "full_jobs = retrieve_full_jobs_by_id(\"oracle xstore pos rollout lead\", k=3)\n",
    "for job in full_jobs:\n",
    "    result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": job}]})\n",
    "    job_summary = result['messages'][-1].content\n",
    "    print(job_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd4ccf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Use a chat model for summarization\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI  # for Gemini\n",
    "# from langchain_openai import ChatOpenAI  # uncomment if you want OpenAI chat\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "class JobMatching:\n",
    "    def __init__(self, model_name: str, job_list_path: str, default_k: int = 5) -> None:\n",
    "        self.model_name = model_name  # e.g. \"google_genai:gemini-2.5-flash-lite\"\n",
    "        self.job_list_path = job_list_path\n",
    "        self.df = None\n",
    "        self.df_by_id = None\n",
    "        self.search_param = default_k\n",
    "\n",
    "        # Embeddings: OpenAI (ensure OPENAI_API_KEY is set)\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "        self.vector_store = None\n",
    "        self.retriever = None\n",
    "\n",
    "    def row_to_doc(self, row):\n",
    "        desc = row.get(\"description\", \"\") if isinstance(row, dict) else row[\"description\"]\n",
    "        content = (\n",
    "            f\"Title: {row['title']}\\n\"\n",
    "            f\"Company: {row['company']}\\n\"\n",
    "            f\"Location: {row['location']}\\n\"\n",
    "            f\"Remote: {row['remote']}\\n\"\n",
    "            f\"Department: {row['department']}\\n\"\n",
    "            f\"Description:\\n{desc}\"\n",
    "        ).strip()\n",
    "        metadata = {\n",
    "            \"doc_id\": row[\"doc_id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"company\": row[\"company\"],\n",
    "            \"location\": row[\"location\"],\n",
    "            \"remote\": row[\"remote\"],\n",
    "            \"department\": row[\"department\"],\n",
    "        }\n",
    "        return Document(page_content=content, metadata=metadata)\n",
    "\n",
    "    def load_joblist(self):\n",
    "        self.df = pd.read_csv(self.job_list_path)\n",
    "        self.df = self.df.fillna(\"\").reset_index(drop=False).rename(columns={\"index\": \"doc_id\"})\n",
    "        self.df[\"doc_id\"] = self.df[\"doc_id\"].astype(str)\n",
    "\n",
    "        base_docs = [self.row_to_doc(r) for _, r in self.df.iterrows()]\n",
    "        print(f\"Loaded {len(base_docs)} base docs\")\n",
    "\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1200,\n",
    "            chunk_overlap=150,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        )\n",
    "\n",
    "        chunked_docs = []\n",
    "        for d in base_docs:\n",
    "            for i, ch in enumerate(splitter.split_text(d.page_content)):\n",
    "                md = dict(d.metadata)\n",
    "                md[\"chunk\"] = i\n",
    "                chunked_docs.append(Document(page_content=ch, metadata=md))\n",
    "\n",
    "        print(f\"Prepared {len(chunked_docs)} chunks\")\n",
    "\n",
    "        self.vector_store = Chroma(\n",
    "            collection_name=\"jobs_rag\",\n",
    "            embedding_function=self.embeddings,\n",
    "            persist_directory=\"./chroma_langchain_n_db\",\n",
    "        )\n",
    "\n",
    "        BATCH_SIZE = 100\n",
    "        ids = []\n",
    "        for i in range(0, len(chunked_docs), BATCH_SIZE):\n",
    "            batch = chunked_docs[i : i + BATCH_SIZE]\n",
    "            ids.extend(self.vector_store.add_documents(batch))\n",
    "\n",
    "        print(\"Example IDs:\", ids[:3])\n",
    "        print(\"Done indexing.\")\n",
    "\n",
    "        self.df_by_id = self.df.set_index(\"doc_id\", drop=False)\n",
    "        self.retriever = self.vector_store.as_retriever(search_kwargs={\"k\": self.search_param})\n",
    "\n",
    "    def format_full_row(self, row):\n",
    "        return (\n",
    "            f\"Title: {row['title']}\\n\"\n",
    "            f\"Company: {row['company']}\\n\"\n",
    "            f\"Location: {row['location']}\\n\"\n",
    "            f\"Remote: {row['remote']}\\n\"\n",
    "            f\"Department: {row['department']}\\n\"\n",
    "            f\"Description:\\n{row['description']}\"\n",
    "        ).strip()\n",
    "\n",
    "    def _get_chat_model(self):\n",
    "        \"\"\"\n",
    "        Returns a chat model instance based on self.model_name.\n",
    "        Default: Gemini via langchain_google_genai.\n",
    "        \"\"\"\n",
    "        # If you want to switch on prefixes, do it here.\n",
    "        # For now assume Gemini name is passed.\n",
    "        return ChatGoogleGenerativeAI(model=self.model_name, temperature=0)\n",
    "\n",
    "        # For OpenAI instead:\n",
    "        # return ChatOpenAI(model=self.model_name, temperature=0)\n",
    "\n",
    "    def refine_result(self, results: list):\n",
    "        chat = self._get_chat_model()\n",
    "\n",
    "        system = (\n",
    "            \"You summarize job descriptions. Return STRICT JSON only with keys: \"\n",
    "            'Company, JobTitle, Remote, Description, Requirements, Email. '\n",
    "            'Remote must be \"yes\" or \"not\". Keep Description ≤ 200 words.'\n",
    "        )\n",
    "\n",
    "        refined = []\n",
    "        for job_text in results:\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system},\n",
    "                {\"role\": \"user\", \"content\": f\"Summarize this job:\\n\\n{job_text}\\n\\nReturn only JSON.\"},\n",
    "            ]\n",
    "            resp = chat.invoke(messages)\n",
    "            refined.append(resp.content.strip())\n",
    "            print(resp.content.strip())\n",
    "        return refined\n",
    "\n",
    "    def exec_query(self, qry_str: str, top_k: int = 5):\n",
    "        # allow per-call k override\n",
    "        retriever = (\n",
    "            self.vector_store.as_retriever(search_kwargs={\"k\": top_k})\n",
    "            if self.vector_store is not None\n",
    "            else self.retriever\n",
    "        )\n",
    "        if retriever is None:\n",
    "            raise RuntimeError(\"Retriever not initialized. Did you call load_joblist()?\")\n",
    "\n",
    "        chunks = retriever.invoke(qry_str)\n",
    "\n",
    "        seen = set()\n",
    "        results = []\n",
    "        for ch in chunks:\n",
    "            did = ch.metadata[\"doc_id\"]\n",
    "            if did in seen:\n",
    "                continue\n",
    "            seen.add(did)\n",
    "            row = self.df_by_id.loc[did]\n",
    "            results.append(self.format_full_row(row))\n",
    "            if len(results) >= top_k:\n",
    "                break\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25da72de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2103 base docs\n",
      "Prepared 12684 chunks\n",
      "Example IDs: ['18dbe568-3e17-4df4-b0da-6348944e4a8c', 'd7ee2a13-444f-477a-af33-201dd357fd2c', 'd02cbd99-7027-4213-a607-a365d4ae17c7']\n",
      "Done indexing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jm = JobMatching(\n",
    "    model_name=\"gemini-2.5-flash-lite\",  # Google Generative AI chat model name\n",
    "    job_list_path=\"joblist_clean_for_rag.csv\",\n",
    ")\n",
    "jm.load_joblist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52bed10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Company\": \"databricks\",\n",
      "  \"JobTitle\": \"Software Engineer - New Grad (2026 Start)\",\n",
      "  \"Remote\": \"not\",\n",
      "  \"Description\": \"Databricks is seeking Software Engineers for new graduate positions starting in 2026. You will join a team building and running the world's best data and AI infrastructure platform. Responsibilities include working on infrastructure and products for the Databricks platform, developing and extending the product, and owning the full software development lifecycle from design to production. You will contribute to building solutions with high reliability, scalability, and security, working collaboratively with experienced engineers and a dedicated mentor.\",\n",
      "  \"Requirements\": \"Graduation between Fall 2025 and Summer 2026 with a degree in Computer Science, Engineering, or a related field. Proficiency in a general-purpose programming language (e.g., Python, Java, C++). Knowledge of algorithms, data structures, and OOP principles. Experience managing end-to-end projects.\",\n",
      "  \"Email\": \"\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "  \"Company\": \"databricks\",\n",
      "  \"JobTitle\": \"Product Manager, New Grad (2026)\",\n",
      "  \"Remote\": \"not\",\n",
      "  \"Description\": \"Databricks is seeking Associate Product Managers to join their team in Berlin, Germany. This role is for new graduates who will graduate between Fall 2025 and Summer 2026. You will work on building features for the Databricks platform, managing projects end-to-end, and learning about scaling a platform while maintaining quality and security. You'll be part of the 2026 APM cohort, receiving mentorship and connecting with various teams across the company. Databricks is a leading data and AI company used by over 10,000 organizations worldwide.\",\n",
      "  \"Requirements\": \"Bachelors or Masters degree in computer science or related engineering practice (graduating Fall 2025 - Summer 2026). Experience with SQL and/or Python. Strong analytical skills for data-driven decisions. Excellent communication skills to simplify complex topics for diverse stakeholders. Collaborative spirit and enthusiasm for solving ambiguous problems.\",\n",
      "  \"Email\": \"\"\n",
      "}\n",
      "```\n",
      "\n",
      "--- SUMMARY ---\n",
      " ```json\n",
      "{\n",
      "  \"Company\": \"databricks\",\n",
      "  \"JobTitle\": \"Software Engineer - New Grad (2026 Start)\",\n",
      "  \"Remote\": \"not\",\n",
      "  \"Description\": \"Databricks is seeking Software Engineers for new graduate positions starting in 2026. You will join a team building and running the world's best data and AI infrastructure platform. Responsibilities include working on infrastructure and products for the Databricks platform, developing and extending the product, and owning the full software development lifecycle from design to production. You will contribute to building solutions with high reliability, scalability, and security, working collaboratively with experienced engineers and a dedicated mentor.\",\n",
      "  \"Requirements\": \"Graduation between Fall 2025 and Summer 2026 with a degree in Computer Science, Engineering, or a related field. Proficiency in a general-purpose programming language (e.g., Python, Java, C++). Knowledge of algorithms, data structures, and OOP principles. Experience managing end-to-end projects.\",\n",
      "  \"Email\": \"\"\n",
      "}\n",
      "```\n",
      "\n",
      "--- SUMMARY ---\n",
      " ```json\n",
      "{\n",
      "  \"Company\": \"databricks\",\n",
      "  \"JobTitle\": \"Product Manager, New Grad (2026)\",\n",
      "  \"Remote\": \"not\",\n",
      "  \"Description\": \"Databricks is seeking Associate Product Managers to join their team in Berlin, Germany. This role is for new graduates who will graduate between Fall 2025 and Summer 2026. You will work on building features for the Databricks platform, managing projects end-to-end, and learning about scaling a platform while maintaining quality and security. You'll be part of the 2026 APM cohort, receiving mentorship and connecting with various teams across the company. Databricks is a leading data and AI company used by over 10,000 organizations worldwide.\",\n",
      "  \"Requirements\": \"Bachelors or Masters degree in computer science or related engineering practice (graduating Fall 2025 - Summer 2026). Experience with SQL and/or Python. Strong analytical skills for data-driven decisions. Excellent communication skills to simplify complex topics for diverse stakeholders. Collaborative spirit and enthusiasm for solving ambiguous problems.\",\n",
      "  \"Email\": \"\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "query = \"skills: python, new graduate, Amsterdam, Computer Science, AI, Data Science\"\n",
    "results = jm.exec_query(query, top_k=5)\n",
    "summaries = jm.refine_result(results)\n",
    "for s in summaries:\n",
    "    print(\"\\n--- SUMMARY ---\\n\", s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
